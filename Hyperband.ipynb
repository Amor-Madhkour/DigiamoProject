{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["pip install keras-tuner --upgrade\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras_tuner.tuners import Hyperband\n","from transformers import BertTokenizer\n","import matplotlib.pyplot as plt\n","\n","# Load data\n","df = pd.read_csv(\"/kaggle/input/japanese-newspapers-20052021/japanese_news.csv\", delimiter='\\t')\n","df['text'] = df['text'].fillna('')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["print(df.head())\n","print(df.info())\n","print(df.columns)\n","\n","percentages = df['source'].value_counts(normalize=True) * 100\n","\n","plt.figure(figsize=(10, 6))\n","percentages.plot(kind='bar', color='skyblue')\n","plt.title('Percentage distribution for {}'.format(source_column))\n","plt.xlabel(source_column)\n","plt.ylabel('Percentage')\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.tight_layout()\n","plt.show()\n","\n","source_counts = df['source'].value_counts()\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=source_counts.index, y=source_counts.values, palette=\"viridis\")\n","plt.title('Source distribution')\n","plt.xlabel('Source')\n","plt.ylabel('Number of articles')\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","\n","df['date'] = pd.to_datetime(df['date'], errors='coerce')\n","\n","invalid_dates = df[df['date'].isnull()]\n","\n","print(\"Rows with invalid dates:\")\n","print(invalid_dates)\n","\n","df = df.dropna(subset=['date'])\n","\n","df['year'] = df['date'].dt.year\n","\n","for year, year_data in df.groupby('year'):\n","    source_counts = year_data['source'].value_counts()\n","\n","    plt.figure(figsize=(10, 6))\n","    sns.barplot(x=source_counts.index, y=source_counts.values, hue=source_counts.index, palette=\"viridis\", legend=False)\n","    plt.title(f'Source distribution - Year {year}')\n","    plt.xlabel('Source')\n","    plt.ylabel('Number of articles')\n","    plt.xticks(rotation=45)\n","    plt.show()\n","    plt.tight_layout()\n","\n","df['year'] = pd.to_datetime(df['date']).dt.year\n","articles_per_year = df['year'].value_counts().sort_index()\n","\n","plt.figure(figsize=(10,6))\n","articles_per_year.plot(kind='line', marker='o')\n","plt.title('Number of articles per year')\n","plt.xlabel('Year')\n","plt.ylabel('Number of articles')\n","plt.xticks(rotation=45)\n","plt.grid(True)\n","plt.show()\n","plt.tight_layout()\n","\n","articles_per_source = df['source'].value_counts()\n","\n","plt.figure(figsize=(10,6))\n","articles_per_source.plot(kind='line', marker='o')\n","plt.title('Number of articles per source')\n","plt.xlabel('Source')\n","plt.ylabel('Number of articles')\n","plt.xticks(rotation=45)\n","plt.show()\n","plt.tight_layout()\n","\n","articles_per_year_and_source = df.groupby(['year', 'source']).size().unstack(fill_value=0)\n","\n","plt.figure(figsize=(18, 12))\n","articles_per_year_and_source.plot(kind='line', marker='o')\n","plt.title('Number of articles per year per source')\n","plt.xlabel('Year')\n","plt.ylabel('Number of articles')\n","plt.xticks(articles_per_year_and_source.index, rotation=45)\n","plt.grid(True)\n","plt.legend(title='Source', bbox_to_anchor=(1, 1))\n","plt.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["desired_sample_size = 250000\n","df_sample = df.sample(n=desired_sample_size, random_state=42)\n","\n","X = df_sample['text']\n","y = df_sample['source']\n","\n","num_unique_sources = df_sample['source'].nunique()\n","print(\"Numero di valori unici nella colonna 'source':\", num_unique_sources)\n","\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":[" \n","tokenizer = BertTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n","X_train_tok = tokenizer(X_train.tolist(), padding=True, truncation=True, max_length=115, return_tensors=\"tf\")\n","X_test_tok = tokenizer(X_test.tolist(), padding=True, truncation=True, max_length=115, return_tensors=\"tf\")\n","\n","max_len = 115  # Adjust according to the distribution of text lengths\n","X_train_pad = pad_sequences(X_train_tok[\"input_ids\"], maxlen=max_len, padding='post')\n","X_test_pad = pad_sequences(X_test_tok[\"input_ids\"], maxlen=max_len, padding='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["\n","def build_model(hp):\n","    model = Sequential()\n","    model.add(Embedding(input_dim=len(tokenizer.vocab), output_dim=200))\n","    model.add(128, 5, activation='relu')\n","    model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.4)))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n","\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n","    return model\n","#{'embedding_output_dim': 200, 'conv1d_filters': 128, 'lstm_units': 128, 'lstm_dropout': 0.30000000000000004, 'recurrent_dropout': 0.4, 'dense_units': 64, 'dropout': 0.2, 'learning_rate': 0.001}\n","# Define the Hyperband tuner\n","tuner = Hyperband(\n","    build_model,\n","    objective='val_accuracy',\n","    max_epochs=15,  \n","    factor=3,  \n","    directory='my_dir',\n","    project_name='japanese_news'\n",")\n","\n","\n","tuner.search(X_train_pad, y_train, epochs=30, validation_data=(X_test_pad, y_test))\n","\n","\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(\"Best Hyperparameters:\")\n","print(best_hps.values)\n","\n","model = tuner.hypermodel.build(best_hps)\n","history = model.fit(X_train_pad, y_train, epochs=30, batch_size=128, validation_data=(X_test_pad, y_test))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["loss, accuracy = model.evaluate(X_test_pad, y_test)\n","print(\"Test Accuracy:\", accuracy)\n","\n","y_pred = model.predict_classes(X_test_pad)\n","\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n","\n","print(\"Confusion Matrix:\")\n","conf_mat = confusion_matrix(y_test, y_pred)\n","print(conf_mat)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false},"outputs":[],"source":["plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2237026,"sourceId":3748403,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
